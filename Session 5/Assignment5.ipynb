{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SJyVpgSxHt4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importing libraries\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add, BatchNormalization\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HzMqbTnxQQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# /255 : To have pixel values in same range\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6sFe4bOQFYP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainy_categorical = np_utils.to_categorical(y_train, 10)\n",
        "testy_categorical = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuST1wo6IL9c",
        "colab_type": "code",
        "outputId": "ac979134-6962-46bd-ecd6-3a07c93e758b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "print(np.shape(X_train))\n",
        "print(np.shape(X_test))\n",
        "# Dataset to have one channel\n",
        "w, h, c = X_train.shape[1], X_train.shape[2], 1\n",
        "X_train = X_train.reshape((X_train.shape[0], w, h, c))\n",
        "X_test = X_test.reshape((X_test.shape[0], w, h, c))\n",
        "print(np.shape(X_train))\n",
        "print(np.shape(X_test))\n",
        "\n",
        "#Mean and SD for Image Normalization\n",
        "print('Statistics train=%.3f (%.3f), test=%.3f (%.3f)' % (X_train.mean(), X_train.std(), X_test.mean(), X_test.std()))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n",
            "(60000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n",
            "Statistics train=0.131 (0.308), test=0.133 (0.310)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1WXW1gaLwUu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Image Normalization\n",
        "from keras.preprocessing.image import ImageDataGenerator \n",
        "\n",
        "# Image generator - centers pixel values\n",
        "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
        "valid_datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
        "\n",
        "datagen.fit(X_train)\n",
        "datagen.fit(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDpXf4YQxXRm",
        "colab_type": "code",
        "outputId": "2fc730bd-8e8f-406a-d9f4-605bdbf77e74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1289
        }
      },
      "source": [
        "#L2 Regulatization\n",
        "#Added Relu activation after batch normalization\n",
        "from keras.layers import Activation\n",
        "from keras.regularizers import l2\n",
        "model = Sequential()\n",
        " \n",
        "# Input image = 28x28 with 1 channel\n",
        "# Convolved with 3x3 with 16 kernels\n",
        "# Output image will be = 26x26 with 16 channels\n",
        "model.add(Convolution2D(16, 3, 3,kernel_regularizer=l2(0.01), input_shape=(28,28,1))) #26\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "#model.add(Dropout(0.1))\n",
        "\n",
        "# Input image = 26x26 with 16 channels\n",
        "# Convolved with 3x3 with 32 kernels\n",
        "# Output image will be = 24x24 with 32 channels\n",
        "model.add(Convolution2D(32, 3, 3,kernel_regularizer=l2(0.01))) #24\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "\n",
        "# Input image = 24x24 with 32 channels\n",
        "# Convolved with 1x1 with 10 kernels\n",
        "# Output image will be = 22x22 with 10 channels\n",
        "model.add(Convolution2D(10, 1, 1,kernel_regularizer=l2(0.01))) #22\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# -----------> Max Pooling <------------------\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))#11\n",
        "\n",
        "# Input image = 12x12 with 10 channels\n",
        "# Convolved with 3x3 with 16 kernels\n",
        "# Output image will be = 10x10 with 16 channels\n",
        "model.add(Convolution2D(16, 3, 3,kernel_regularizer=l2(0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "#model.add(Dropout(0.1))\n",
        "\n",
        "# Input image = 10x10 with 16 channels\n",
        "# Convolved with 3x3 with 16 kernels\n",
        "# Output image will be = 8x8 with 16 channels\n",
        "model.add(Convolution2D(16, 3, 3,kernel_regularizer=l2(0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "#model.add(Dropout(0.1))\n",
        "\n",
        "# Input image =8x8 with 16 channels\n",
        "# Convolved with 3x3 with 16 kernels\n",
        "# Output image will be = 6x6 with 16 channels\n",
        "model.add(Convolution2D(16, 3, 3,kernel_regularizer=l2(0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "\n",
        "# Input image = 6x6 with 16 channels\n",
        "# Convolved with 3x3 with 16 kernels\n",
        "# Output image will be = 4x4 with 16 channels\n",
        "model.add(Convolution2D(16, 3, 3,kernel_regularizer=l2(0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "#model.add(Dropout(0.1))\n",
        "\n",
        "# Input image = 4x4 with 16 channels\n",
        "# Convolved with 4x4 with 10 kernels\n",
        "# Output image will be = 1x1 with 10 channels\n",
        "model.add(Convolution2D(10, 4, 4))\n",
        "model.add(BatchNormalization())\n",
        "#model.add(Dropout(0.1))\n",
        "\n",
        "# Last Layer\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), kernel_regularizer=<keras.reg..., input_shape=(28, 28, 1...)`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), kernel_regularizer=<keras.reg...)`\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:57: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (4, 4))`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 24, 24, 32)        4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 24, 24, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 24, 24, 10)        330       \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 24, 24, 10)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 10, 10, 16)        1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 10, 10, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 8, 8, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 8, 8, 16)          64        \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 6, 6, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 6, 6, 16)          64        \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 6, 6, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 4, 4, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 4, 4, 16)          64        \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 1, 1, 10)          2570      \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 1, 1, 10)          40        \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 16,604\n",
            "Trainable params: 16,360\n",
            "Non-trainable params: 244\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2IicGJ4x3Be",
        "colab_type": "code",
        "outputId": "e674b46d-2546-4af3-c1c6-25a7c2a05f6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4614
        }
      },
      "source": [
        "#Checkpoint to save the model with best val accuracy\n",
        "# Learning rate scheduler\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.callbacks import *\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])\n",
        "filepath='./Assignemnt5.hdf5'\n",
        "checkpoint = ModelCheckpoint(filepath, monitor = 'val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='max',  period=1)\n",
        "model.fit_generator(datagen.flow(X_train, trainy_categorical, batch_size=512),\n",
        "                    steps_per_epoch=len(X_train) / 512, \n",
        "                    epochs=40,validation_data=valid_datagen.flow(X_test, testy_categorical, batch_size=128),\n",
        "                   callbacks=[LearningRateScheduler(scheduler, verbose=1),checkpoint],\n",
        "                   validation_steps=64)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:699: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n",
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:707: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "118/117 [==============================] - 5s 44ms/step - loss: 1.1106 - acc: 0.9090 - val_loss: 2.5163 - val_acc: 0.0881\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.08813, saving model to ./Assignemnt5.hdf5\n",
            "Epoch 2/40\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "118/117 [==============================] - 3s 27ms/step - loss: 0.3150 - acc: 0.9840 - val_loss: 2.3932 - val_acc: 0.0920\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.08813 to 0.09196, saving model to ./Assignemnt5.hdf5\n",
            "Epoch 3/40\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "118/117 [==============================] - 3s 26ms/step - loss: 0.1896 - acc: 0.9867 - val_loss: 2.1949 - val_acc: 0.1764\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.09196 to 0.17636, saving model to ./Assignemnt5.hdf5\n",
            "Epoch 4/40\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "118/117 [==============================] - 3s 26ms/step - loss: 0.1421 - acc: 0.9894 - val_loss: 1.9234 - val_acc: 0.2911\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.17636 to 0.29109, saving model to ./Assignemnt5.hdf5\n",
            "Epoch 5/40\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "118/117 [==============================] - 3s 26ms/step - loss: 0.1193 - acc: 0.9899 - val_loss: 1.8335 - val_acc: 0.3380\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.29109 to 0.33800, saving model to ./Assignemnt5.hdf5\n",
            "Epoch 6/40\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "118/117 [==============================] - 3s 26ms/step - loss: 0.1034 - acc: 0.9904 - val_loss: 1.5124 - val_acc: 0.4305\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.33800 to 0.43054, saving model to ./Assignemnt5.hdf5\n",
            "Epoch 7/40\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "118/117 [==============================] - 3s 26ms/step - loss: 0.0938 - acc: 0.9916 - val_loss: 0.8149 - val_acc: 0.7764\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.43054 to 0.77636, saving model to ./Assignemnt5.hdf5\n",
            "Epoch 8/40\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "118/117 [==============================] - 3s 26ms/step - loss: 0.0827 - acc: 0.9924 - val_loss: 0.5037 - val_acc: 0.8874\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.77636 to 0.88738, saving model to ./Assignemnt5.hdf5\n",
            "Epoch 9/40\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "118/117 [==============================] - 3s 26ms/step - loss: 0.0771 - acc: 0.9924 - val_loss: 0.7364 - val_acc: 0.7740\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.88738\n",
            "Epoch 10/40\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "118/117 [==============================] - 3s 26ms/step - loss: 0.0706 - acc: 0.9931 - val_loss: 0.6939 - val_acc: 0.7952\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.88738\n",
            "Epoch 11/40\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "118/117 [==============================] - 3s 26ms/step - loss: 0.0675 - acc: 0.9930 - val_loss: 0.2317 - val_acc: 0.9640\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.88738 to 0.96399, saving model to ./Assignemnt5.hdf5\n",
            "Epoch 12/40\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "118/117 [==============================] - 3s 26ms/step - loss: 0.0631 - acc: 0.9934 - val_loss: 0.4042 - val_acc: 0.8952\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.96399\n",
            "Epoch 13/40\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "118/117 [==============================] - 3s 26ms/step - loss: 0.0603 - acc: 0.9939 - val_loss: 0.3458 - val_acc: 0.9276\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.96399\n",
            "Epoch 14/40\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "118/117 [==============================] - 3s 26ms/step - loss: 0.0571 - acc: 0.9942 - val_loss: 0.2386 - val_acc: 0.9491\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.96399\n",
            "Epoch 15/40\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "118/117 [==============================] - 3s 26ms/step - loss: 0.0551 - acc: 0.9945 - val_loss: 0.3846 - val_acc: 0.8969\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.96399\n",
            "Epoch 16/40\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "118/117 [==============================] - 3s 26ms/step - loss: 0.0495 - acc: 0.9953 - val_loss: 0.2861 - val_acc: 0.9417\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.96399\n",
            "Epoch 17/40\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "118/117 [==============================] - 3s 26ms/step - loss: 0.0473 - acc: 0.9954 - val_loss: 0.3457 - val_acc: 0.9194\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.96399\n",
            "Epoch 18/40\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "118/117 [==============================] - 3s 26ms/step - loss: 0.0459 - acc: 0.9955 - val_loss: 0.4933 - val_acc: 0.8427\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.96399\n",
            "Epoch 19/40\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "118/117 [==============================] - 3s 26ms/step - loss: 0.0458 - acc: 0.9952 - val_loss: 0.2116 - val_acc: 0.9605\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.96399\n",
            "Epoch 20/40\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "118/117 [==============================] - 3s 26ms/step - loss: 0.0438 - acc: 0.9955 - val_loss: 0.3249 - val_acc: 0.9108\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.96399\n",
            "Epoch 21/40\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0004065041.\n",
            "118/117 [==============================] - 3s 26ms/step - loss: 0.0413 - acc: 0.9960 - val_loss: 0.4713 - val_acc: 0.8662\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.96399\n",
            "Epoch 22/40\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000389661.\n",
            "118/117 [==============================] - 3s 26ms/step - loss: 0.0383 - acc: 0.9964 - val_loss: 0.2571 - val_acc: 0.9340\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.96399\n",
            "Epoch 23/40\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0003741581.\n",
            "118/117 [==============================] - 3s 26ms/step - loss: 0.0369 - acc: 0.9965 - val_loss: 0.4021 - val_acc: 0.9032\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.96399\n",
            "Epoch 24/40\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0003598417.\n",
            "118/117 [==============================] - 3s 26ms/step - loss: 0.0378 - acc: 0.9966 - val_loss: 0.1671 - val_acc: 0.9653\n",
            "\n",
            "Epoch 00024: val_acc improved from 0.96399 to 0.96535, saving model to ./Assignemnt5.hdf5\n",
            "Epoch 25/40\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0003465804.\n",
            "118/117 [==============================] - 3s 26ms/step - loss: 0.0366 - acc: 0.9964 - val_loss: 0.2467 - val_acc: 0.9438\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.96535\n",
            "Epoch 26/40\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0003342618.\n",
            "118/117 [==============================] - 3s 26ms/step - loss: 0.0356 - acc: 0.9963 - val_loss: 0.5134 - val_acc: 0.8327\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.96535\n",
            "Epoch 27/40\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0003227889.\n",
            "118/117 [==============================] - 3s 26ms/step - loss: 0.0319 - acc: 0.9975 - val_loss: 0.9790 - val_acc: 0.6669\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.96535\n",
            "Epoch 28/40\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0003120774.\n",
            "118/117 [==============================] - 3s 26ms/step - loss: 0.0308 - acc: 0.9975 - val_loss: 0.6969 - val_acc: 0.7629\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.96535\n",
            "Epoch 29/40\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000302054.\n",
            "118/117 [==============================] - 3s 26ms/step - loss: 0.0296 - acc: 0.9975 - val_loss: 0.2746 - val_acc: 0.9230\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.96535\n",
            "Epoch 30/40\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0002926544.\n",
            "118/117 [==============================] - 3s 26ms/step - loss: 0.0303 - acc: 0.9972 - val_loss: 0.2367 - val_acc: 0.9345\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.96535\n",
            "Epoch 31/40\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0002838221.\n",
            "118/117 [==============================] - 3s 26ms/step - loss: 0.0293 - acc: 0.9974 - val_loss: 0.3170 - val_acc: 0.9142\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.96535\n",
            "Epoch 32/40\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0002755074.\n",
            "118/117 [==============================] - 3s 26ms/step - loss: 0.0272 - acc: 0.9979 - val_loss: 0.3771 - val_acc: 0.8905\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.96535\n",
            "Epoch 33/40\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.000267666.\n",
            "118/117 [==============================] - 3s 26ms/step - loss: 0.0279 - acc: 0.9973 - val_loss: 0.2959 - val_acc: 0.9136\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.96535\n",
            "Epoch 34/40\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0002602585.\n",
            "118/117 [==============================] - 3s 26ms/step - loss: 0.0257 - acc: 0.9981 - val_loss: 0.3431 - val_acc: 0.8958\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.96535\n",
            "Epoch 35/40\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.00025325.\n",
            "118/117 [==============================] - 3s 26ms/step - loss: 0.0255 - acc: 0.9979 - val_loss: 0.1600 - val_acc: 0.9635\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.96535\n",
            "Epoch 36/40\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0002466091.\n",
            "118/117 [==============================] - 3s 26ms/step - loss: 0.0229 - acc: 0.9986 - val_loss: 0.1893 - val_acc: 0.9551\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.96535\n",
            "Epoch 37/40\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0002403076.\n",
            "118/117 [==============================] - 3s 26ms/step - loss: 0.0216 - acc: 0.9989 - val_loss: 0.2002 - val_acc: 0.9501\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.96535\n",
            "Epoch 38/40\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0002343201.\n",
            "118/117 [==============================] - 3s 26ms/step - loss: 0.0218 - acc: 0.9985 - val_loss: 0.2145 - val_acc: 0.9386\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.96535\n",
            "Epoch 39/40\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0002286237.\n",
            "118/117 [==============================] - 3s 26ms/step - loss: 0.0219 - acc: 0.9984 - val_loss: 0.2289 - val_acc: 0.9307\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.96535\n",
            "Epoch 40/40\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0002231977.\n",
            "118/117 [==============================] - 3s 26ms/step - loss: 0.0215 - acc: 0.9984 - val_loss: 0.2604 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.96535\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f345dd25f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLxlW9ufyQiO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "3f91472b-c65c-43b3-b9e3-596fd13c8e68"
      },
      "source": [
        "#Getting the best model and working on that\n",
        "from keras.models import load_model\n",
        "from keras.optimizers import Adam\n",
        "model = load_model('Assignemnt5.hdf5')\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])\n",
        "score = model.evaluate(X_test, testy_categorical, verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.1630799171566963, 0.9672]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2qDl21ozBnW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Predicting the values of the test data \n",
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPWpfbWTwtyD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "outputId": "4f14f748-a9ca-49b8-e972-c904620438b3"
      },
      "source": [
        "print(y_pred[:10])\n",
        "print(y_test[:10])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.21411169e-03 8.19021021e-04 1.20440207e-03 3.04241985e-04\n",
            "  6.13191165e-04 7.07692176e-04 1.38540316e-04 9.93388772e-01\n",
            "  3.37282981e-04 1.27273065e-03]\n",
            " [1.24972332e-02 2.53250059e-02 9.35515046e-01 4.80561238e-03\n",
            "  3.93022259e-04 2.13586236e-03 1.30128758e-02 2.41997209e-03\n",
            "  2.71752430e-03 1.17778720e-03]\n",
            " [5.42951515e-04 9.88962710e-01 9.35702003e-04 3.86382046e-04\n",
            "  5.84693626e-04 1.29569601e-03 1.09419168e-03 3.21909506e-03\n",
            "  3.76349839e-04 2.60237954e-03]\n",
            " [9.93575871e-01 6.75066607e-04 1.09269575e-04 8.49569566e-04\n",
            "  1.10433996e-03 4.32385976e-04 5.80387539e-04 1.45652192e-03\n",
            "  1.05046958e-03 1.66201353e-04]\n",
            " [5.97841339e-03 3.36345881e-02 5.85054001e-03 4.16348176e-03\n",
            "  9.24209297e-01 3.37429205e-03 4.78234934e-03 5.56205027e-03\n",
            "  1.54606253e-03 1.08989105e-02]\n",
            " [7.41438009e-04 9.85143244e-01 1.06104033e-03 6.97104260e-04\n",
            "  6.74561772e-04 1.20456051e-03 1.50464359e-03 5.76046715e-03\n",
            "  5.56623912e-04 2.65635154e-03]\n",
            " [5.76946361e-04 1.44197885e-02 1.56674813e-03 1.55900361e-03\n",
            "  9.48108792e-01 3.35206510e-03 1.22478860e-03 1.56257693e-02\n",
            "  9.24828462e-03 4.31782706e-03]\n",
            " [5.76421618e-03 1.00015476e-02 1.05080856e-02 4.13127476e-03\n",
            "  1.44887149e-01 1.81548242e-02 1.20927370e-03 6.89700153e-03\n",
            "  4.68617640e-02 7.51584828e-01]\n",
            " [1.12579893e-02 1.12156651e-03 1.18234451e-03 1.40181603e-02\n",
            "  2.14176741e-03 7.14653373e-01 2.10696533e-01 3.48798446e-02\n",
            "  8.29169340e-03 1.75669615e-03]\n",
            " [2.54476839e-03 2.83528771e-03 2.47137039e-03 1.91054691e-03\n",
            "  8.54978263e-02 6.54705008e-03 7.08201609e-04 1.56044224e-02\n",
            "  1.90706905e-02 8.62809896e-01]]\n",
            "[7 2 1 0 4 1 4 9 5 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vr3FVE6yOl7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "dd0577e0-cc99-4d6e-af83-a048e15097a7"
      },
      "source": [
        "# Calculating maximum value's indices at every row\n",
        "# Get the first 25 wrong predicted images here\n",
        "PredictedValues = np.argmax(y_pred, axis=1)\n",
        "print(np.shape(PredictedValues))\n",
        "print(np.shape(y_test))\n",
        "indices = list()\n",
        "# getting all the samples for which model predicted wrongly\n",
        "for i in range(10000):\n",
        "  if(PredictedValues[i] != y_test[i]):\n",
        "    indices.append(i)\n",
        "  \n",
        "# First 25 wrongly predicted image indices\n",
        "print(indices[:25])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000,)\n",
            "(10000,)\n",
            "[11, 18, 33, 66, 78, 104, 115, 151, 160, 175, 193, 259, 318, 321, 325, 341, 359, 366, 421, 443, 445, 449, 450, 462, 464]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmjbsQxX6SO_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "outputId": "4098f9c6-1a46-4049-98b6-9a2ae70ad9b7"
      },
      "source": [
        "(X_train_load, y_train_load), (X_test_load, y_test_load) = mnist.load_data()\n",
        "#Form the grid\n",
        "output  = np.concatenate((X_test_load[indices[0]],X_test_load[indices[1]],X_test_load[indices[2]],X_test_load[indices[3]],X_test_load[indices[4]]),axis=1)\n",
        "output1 = np.concatenate((X_test_load[indices[5]],X_test_load[indices[6]],X_test_load[indices[7]],X_test_load[indices[8]],X_test_load[indices[9]]),axis=1)\n",
        "output2 = np.concatenate((X_test_load[indices[10]],X_test_load[indices[11]],X_test_load[indices[12]],X_test_load[indices[13]],X_test_load[indices[14]]),axis=1)\n",
        "output3 = np.concatenate((X_test_load[indices[15]],X_test_load[indices[16]],X_test_load[indices[17]],X_test_load[indices[18]],X_test_load[indices[19]]),axis=1)\n",
        "output4 = np.concatenate((X_test_load[indices[20]],X_test_load[indices[21]],X_test_load[indices[22]],X_test_load[indices[23]],X_test_load[indices[24]]),axis=1)\n",
        "final_output = img = np.concatenate((output,output1,output2,output3,output4), axis=0)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline        \n",
        "# Final matrix\n",
        "plt.imshow(final_output)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f345a0d0588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYcmpLOwGLZk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}